{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_summary_\\n        Implemtaciones posibles:\\n            Tooling: \\n                Chatbot? M√≠neria de textos, de alguna red social, gmail, sistema de control?\\n            Institucional: \\n                Ser√≠a √∫til para las empresas en detectar conductas inapropiadas tales como racismo,\\n                machismo, acoso sexual, por medios oficiales de comunicaci√≥n.\\n                    datasets = machismo, acoso sexual, racismo, xenofobia\\n                Implementado como un sistema de control parental, para controlar textos peligrosos\\n                    datasets? \\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se har√° un modelo capaz de reconocer conductas inapropiadas \n",
    "\"\"\"_summary_\n",
    "        Implemtaciones posibles:\n",
    "            Tooling: \n",
    "                Chatbot? M√≠neria de textos, de alguna red social, gmail, sistema de control?\n",
    "            Institucional: \n",
    "                Ser√≠a √∫til para las empresas en detectar conductas inapropiadas tales como racismo,\n",
    "                machismo, acoso sexual, por medios oficiales de comunicaci√≥n.\n",
    "                    datasets = machismo, acoso sexual, racismo, xenofobia\n",
    "                Implementado como un sistema de control parental, para controlar textos peligrosos\n",
    "                    datasets? \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/Documentos/SIC25es-CodeSerpents/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-25 23:15:06.354884: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-25 23:15:06.362569: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 23:15:06.415199: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 23:15:06.461473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742966106.506109    5107 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742966106.519891    5107 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742966106.607667    5107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742966106.607705    5107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742966106.607707    5107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742966106.607709    5107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-25 23:15:06.618994: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/alexander/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importes\n",
    "import kagglehub\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/alexander/.cache/kagglehub/datasets/rishabhjohri/racismdetectiondataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "#Ac√° ir√°n los datasets, ahorita en concepto de uso\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Es un dataset que nos permite detectar textos racistas, en base al target:\n",
    "    target inicial {1:is racist, 0:non-racist}\n",
    "\"\"\"\n",
    "path = kagglehub.dataset_download(\"rishabhjohri/racismdetectiondataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 1999\n",
      "Columnas: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was born a racist and I will die a racist I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitch nigga miss me with that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you aint bout that murder game pussy nigga ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gay niggas couldnt wait to act like bitches to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why deos a gorilla always have a frown because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Label\n",
       "0  i was born a racist and I will die a racist I ...      1\n",
       "1                      bitch nigga miss me with that      1\n",
       "2  if you aint bout that murder game pussy nigga ...      1\n",
       "3  gay niggas couldnt wait to act like bitches to...      1\n",
       "4  why deos a gorilla always have a frown because...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_racism = pd.read_csv('../data_sets/behaviors_data/RacismDetectionDataSet.csv')\n",
    "rows , columns = df_racism.shape\n",
    "print(f'Filas: {rows}\\nColumnas: {columns}')\n",
    "df_racism.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos las etiquetas, y las columnas\n",
    "# text -- emotion\n",
    "\n",
    "df_racism = df_racism.rename(columns={'Comment':'text', 'Label':'emotion'})\n",
    "df_racism['emotion'] = df_racism['emotion'].replace({1:'racist'})\n",
    "df_racism = df_racism[df_racism['emotion'] != 0]\n",
    " #Quitaremos los 0, para el modelo ya entrenado en neutral?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['racist'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_racism['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/alexander/.cache/kagglehub/datasets/saifulislam7/cyberbullying-and-harassment-detection-using-ml/versions/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ten outside soon doctor shake everyone treatme...</td>\n",
       "      <td>Not-Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my life has come to a standstill and at this p...</td>\n",
       "      <td>Not-Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl this nigga make me sick to my stomach</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanna fuck you</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh hey, you should be ashamed of your disgusti...</td>\n",
       "      <td>Not - Bullying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>Please help this Christian nationalist battle ...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Vocational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>Has the Holy Quran ever been read by the membe...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>And that is the difficulty - you need basic gu...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>As they will only encounter Muslim women, help...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>Never try to win. Not just politics, however. ...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8452 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text           Label  \\\n",
       "0     Ten outside soon doctor shake everyone treatme...    Not-Bullying   \n",
       "1     my life has come to a standstill and at this p...    Not-Bullying   \n",
       "2            girl this nigga make me sick to my stomach        Bullying   \n",
       "3                                      I wanna fuck you        Bullying   \n",
       "4     Oh hey, you should be ashamed of your disgusti...  Not - Bullying   \n",
       "...                                                 ...             ...   \n",
       "8447  Please help this Christian nationalist battle ...        Bullying   \n",
       "8448  Has the Holy Quran ever been read by the membe...        Bullying   \n",
       "8449  And that is the difficulty - you need basic gu...        Bullying   \n",
       "8450  As they will only encounter Muslim women, help...        Bullying   \n",
       "8451  Never try to win. Not just politics, however. ...        Bullying   \n",
       "\n",
       "           Types  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2      Ethnicity  \n",
       "3         Sexual  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "8447  Vocational  \n",
       "8448      Sexual  \n",
       "8449    Religion  \n",
       "8450    Religion  \n",
       "8451    Religion  \n",
       "\n",
       "[8452 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"_summary_\n",
    "    Este dataset nos permite identificar bullyng en comentarios\n",
    "    \"\"\"\n",
    "\n",
    "path = kagglehub.dataset_download(\"saifulislam7/cyberbullying-and-harassment-detection-using-ml\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "df_discg = pd.read_csv('../data_sets/behaviors_data/discrimination_variety.csv')\n",
    "df_discg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 8452\n",
      "Columnas: 2\n",
      "['Not-Bullying' 'Bullying']\n"
     ]
    }
   ],
   "source": [
    "rows, colums = df_discg.shape\n",
    "print(f'Filas: {rows}\\nColumnas: {columns}')\n",
    "df_discg['Label'] = df_discg['Label'].replace({'Not - Bullying':'Not-Bullyng','Not -Bullying':'Not-Bullying','Not- Bullying':'Not-Bullying',\n",
    "                                              'Not-Bulying':'Not-Bullying','Not-Bullyng':'Not-Bullying','Not-Bulllying':'Not-Bullying',\n",
    "                                              'Not- Bullying ':'Not-Bullying','Not-Bullying ':'Not-Bullying','Not -Bullying ':'Not-Bullying',\n",
    "                                              'Not-Bullyng':'Not-Bullying','Not-Bulyying':'Not-Bullying',\n",
    "                                              'Bulling ':'Bullying','Bullying.':'Bullying','Bullyibg':'Bullying','Bullying  ':'Bullying',\n",
    "                                              'Bullyiing':'Bullying','Bullying ':'Bullying','Bullyiing':'Bullying','Bullyinfg':'Bullying'})\n",
    "df_discg.loc[df_discg['Label'] == 'Not-Bullying', 'Types'] = 'Neutral'\n",
    "\n",
    "df_discg = df_discg.dropna()\n",
    "#print(df_discg['Types'].unique())\n",
    "print(df_discg['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ten outside soon doctor shake everyone treatme...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my life has come to a standstill and at this p...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl this nigga make me sick to my stomach</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanna fuck you</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Haha isn't route running part of the position?...</td>\n",
       "      <td>Ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>Please help this Christian nationalist battle ...</td>\n",
       "      <td>Vocational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>Has the Holy Quran ever been read by the membe...</td>\n",
       "      <td>Sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>And that is the difficulty - you need basic gu...</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>As they will only encounter Muslim women, help...</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>Never try to win. Not just politics, however. ...</td>\n",
       "      <td>Religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8172 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     emotion\n",
       "0     Ten outside soon doctor shake everyone treatme...     Neutral\n",
       "1     my life has come to a standstill and at this p...     Neutral\n",
       "2            girl this nigga make me sick to my stomach   Ethnicity\n",
       "3                                      I wanna fuck you      Sexual\n",
       "5     Haha isn't route running part of the position?...   Ethnicity\n",
       "...                                                 ...         ...\n",
       "8447  Please help this Christian nationalist battle ...  Vocational\n",
       "8448  Has the Holy Quran ever been read by the membe...      Sexual\n",
       "8449  And that is the difficulty - you need basic gu...    Religion\n",
       "8450  As they will only encounter Muslim women, help...    Religion\n",
       "8451  Never try to win. Not just politics, however. ...    Religion\n",
       "\n",
       "[8172 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limpieza -> uniformidad de datos\n",
    "df_discg = df_discg.rename(columns={'Text':'text','Types':'emotion'})\n",
    "df_discg = df_discg.drop('Label', axis=1)\n",
    "df_discg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/alexander/.cache/kagglehub/datasets/aadyasingh55/sexism-detection-in-english-texts/versions/1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"_summary_\n",
    "    Acoso sexual, etiquetas expl√≠citas\n",
    "    \"\"\"\n",
    "\n",
    "path = kagglehub.dataset_download(\"aadyasingh55/sexism-detection-in-english-texts\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-9609</td>\n",
       "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-966</td>\n",
       "      <td>I bet she wished she had a gun</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-3553</td>\n",
       "      <td>I agree with that but at the same time I know ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.1 descriptive attacks</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-13328</td>\n",
       "      <td>democrats from Minnesota (leftist muzzie shith...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.2 aggressive and emotive attacks</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-81</td>\n",
       "      <td>Texas jury sentences Jordanian immigrant to de...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>sexism2022_english-12034</td>\n",
       "      <td>I blew a shot at a record like that. Girl on t...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>sexism2022_english-5228</td>\n",
       "      <td>girls really get fucked almost every weekend ?</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>sexism2022_english-10140</td>\n",
       "      <td>The hatred for moslems are Reasonable and Just...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>sexism2022_english-9726</td>\n",
       "      <td>Now this is a woman who gets it. üëÜ</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>sexism2022_english-13365</td>\n",
       "      <td>‚ÄúAmerican Idol‚Äù finalist [USER] said nothing i...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rewire_id  \\\n",
       "0       sexism2022_english-9609   \n",
       "1        sexism2022_english-966   \n",
       "2       sexism2022_english-3553   \n",
       "3      sexism2022_english-13328   \n",
       "4         sexism2022_english-81   \n",
       "...                         ...   \n",
       "19995  sexism2022_english-12034   \n",
       "19996   sexism2022_english-5228   \n",
       "19997  sexism2022_english-10140   \n",
       "19998   sexism2022_english-9726   \n",
       "19999  sexism2022_english-13365   \n",
       "\n",
       "                                                    text label_sexist  \\\n",
       "0      In Nigeria, if you rape a woman, the men rape ...   not sexist   \n",
       "1                         I bet she wished she had a gun   not sexist   \n",
       "2      I agree with that but at the same time I know ...       sexist   \n",
       "3      democrats from Minnesota (leftist muzzie shith...       sexist   \n",
       "4      Texas jury sentences Jordanian immigrant to de...   not sexist   \n",
       "...                                                  ...          ...   \n",
       "19995  I blew a shot at a record like that. Girl on t...   not sexist   \n",
       "19996     girls really get fucked almost every weekend ?   not sexist   \n",
       "19997  The hatred for moslems are Reasonable and Just...   not sexist   \n",
       "19998                 Now this is a woman who gets it. üëÜ   not sexist   \n",
       "19999  ‚ÄúAmerican Idol‚Äù finalist [USER] said nothing i...   not sexist   \n",
       "\n",
       "      label_category                        label_vector  split  \n",
       "0               none                                none    dev  \n",
       "1               none                                none    dev  \n",
       "2      2. derogation             2.1 descriptive attacks    dev  \n",
       "3      2. derogation  2.2 aggressive and emotive attacks    dev  \n",
       "4               none                                none    dev  \n",
       "...              ...                                 ...    ...  \n",
       "19995           none                                none  train  \n",
       "19996           none                                none  train  \n",
       "19997           none                                none  train  \n",
       "19998           none                                none  train  \n",
       "19999           none                                none  train  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sexh1 = pd.read_csv('../data_sets/behaviors_data/sexual_harassment1.csv')\n",
    "df_sexh2 = pd.read_csv('../data_sets/behaviors_data/sexual_harassment2.csv')\n",
    "df_sexh3 = pd.read_csv('../data_sets/behaviors_data/sexual_harassment3.csv')\n",
    "df_sexh1\n",
    "\n",
    "df_sexh = pd.concat([df_sexh1,df_sexh2,df_sexh3], ignore_index=True)\n",
    "df_sexh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I agree with that but at the same time I know ...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>democrats from Minnesota (leftist muzzie shith...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aim for the head so she dosn't come back</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This guys gonna have a great time in the barra...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Or women can stop being lying whores.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>The drama queen is just another open borders c...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>This is easily the dumbest thing ever written....</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>Recently some thots started advertizing their ...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>I wish yall understand what a burden it can be...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>idiocracy always seems to be female. Best evid...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4854 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label_sexist\n",
       "2      I agree with that but at the same time I know ...       sexist\n",
       "3      democrats from Minnesota (leftist muzzie shith...       sexist\n",
       "7               aim for the head so she dosn't come back       sexist\n",
       "9      This guys gonna have a great time in the barra...       sexist\n",
       "13                 Or women can stop being lying whores.       sexist\n",
       "...                                                  ...          ...\n",
       "19968  The drama queen is just another open borders c...       sexist\n",
       "19985  This is easily the dumbest thing ever written....       sexist\n",
       "19986  Recently some thots started advertizing their ...       sexist\n",
       "19988  I wish yall understand what a burden it can be...       sexist\n",
       "19993  idiocracy always seems to be female. Best evid...       sexist\n",
       "\n",
       "[4854 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sexh = df_sexh.drop('rewire_id',axis=1)\n",
    "df_sexh = df_sexh.drop('label_category',axis=1)\n",
    "df_sexh = df_sexh.drop('label_vector',axis=1)\n",
    "df_sexh = df_sexh.drop('split',axis=1)\n",
    "df_sexh = df_sexh[df_sexh['label_sexist'] != 'not sexist']\n",
    "\n",
    "df_sexh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 4854\n",
      "Columnas: 2\n",
      "['sexist']\n"
     ]
    }
   ],
   "source": [
    "#Rename\n",
    "df_sexh = df_sexh.rename(columns={'label_sexist':'emotion'})\n",
    "rows, columns = df_sexh.shape\n",
    "print(f'Filas: {rows}\\nColumnas: {columns}')\n",
    "print(df_sexh['emotion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores target: ['Neutral' 'Xenophobic' 'Sexist']\n",
      "emotion\n",
      "Sexist        5882\n",
      "Neutral       3365\n",
      "Xenophobic    1950\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenar todos los dataSets en uno solo\n",
    "#La categor√≠a political se eliminar√°, son muy ambiguos\n",
    "df = pd.concat([ df_discg, df_racism,df_sexh], ignore_index=True)\n",
    "rows, columns = df.shape\n",
    "df = df.dropna()\n",
    "df['emotion'] = df['emotion'].replace({'sexual':'Sexist','Saxual':'Sexist','sexist':'Sexist','Sexual ':'Sexist','Sexual':'Sexist',\n",
    "                                       'Ethnicity':'Xenophobic','Ethnicity ':'Xenophobic','Religion':'Xenophobic','Religion ':'Xenophobic','Ethnically ':'Xenophobic',\n",
    "                                       'racist':'Racist','Racism':'Racist',\n",
    "                                       'Threats ':'Threats','Threat':'Threats','Threat ':'Threats','Religon':'Xenophobic','Religious ':'Xenophobic',\n",
    "                                       'Religious':'Xenophobic','Religion':'Xenophobic','political':'Political','Political ':'Political',\n",
    "                                       'Vocation':'Vocational','Vocational ':'Vocational','political ':'Political','Troll ':'Troll'})\n",
    "df['emotion'] = df['emotion'].replace({'Vocational':'Troll','Racist':'Xenophobic'})\n",
    "#Categor√≠as a contar, Neutral, Xenophobic, Sexist, Threats Troll Same Vocational\n",
    "\n",
    "df = df[df['emotion'] != 'Political']\n",
    "df = df[df['emotion'] != 'Threats']\n",
    "df = df[df['emotion'] != 'Troll']\n",
    "\n",
    "n_cat = df['emotion'].value_counts()\n",
    "\n",
    "n_target = df['emotion'].unique()\n",
    "print(f'Valores target: {n_target}')\n",
    "print(n_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ten outside soon doctor shake everyone treatme...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my life has come to a standstill and at this p...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl this nigga make me sick to my stomach</td>\n",
       "      <td>Xenophobic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanna fuck you</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haha isn't route running part of the position?...</td>\n",
       "      <td>Xenophobic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>The drama queen is just another open borders c...</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14022</th>\n",
       "      <td>This is easily the dumbest thing ever written....</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023</th>\n",
       "      <td>Recently some thots started advertizing their ...</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>I wish yall understand what a burden it can be...</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14025</th>\n",
       "      <td>idiocracy always seems to be female. Best evid...</td>\n",
       "      <td>Sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11197 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     emotion\n",
       "0      Ten outside soon doctor shake everyone treatme...     Neutral\n",
       "1      my life has come to a standstill and at this p...     Neutral\n",
       "2             girl this nigga make me sick to my stomach  Xenophobic\n",
       "3                                       I wanna fuck you      Sexist\n",
       "4      Haha isn't route running part of the position?...  Xenophobic\n",
       "...                                                  ...         ...\n",
       "14021  The drama queen is just another open borders c...      Sexist\n",
       "14022  This is easily the dumbest thing ever written....      Sexist\n",
       "14023  Recently some thots started advertizing their ...      Sexist\n",
       "14024  I wish yall understand what a burden it can be...      Sexist\n",
       "14025  idiocracy always seems to be female. Best evid...      Sexist\n",
       "\n",
       "[11197 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de los valores\n",
    "#Sin√≥nimos sexual-Sexual,Saxual\n",
    "#ethicall... Religion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos t√©cnicas de PLN al df\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "def tokenize_steam(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w.isalnum()]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neutral' 'Xenophobic' 'Sexist']\n"
     ]
    }
   ],
   "source": [
    "#Diccionarios de reglas?\n",
    "#Arquitectura, SVM, RedNeuronal?    \n",
    "#Separamos los textos y las emociones \n",
    "all_words = []\n",
    "df['text'].apply(lambda x: all_words.extend(tokenize_steam(x)))  # Agregamos palabra por palabra\n",
    "all_words = sorted(set(all_words))\n",
    "\n",
    "x = df['text']\n",
    "y = df['emotion']\n",
    "\n",
    "print(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/Documentos/SIC25es-CodeSerpents/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-25 23:15:14.541494: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6545 - loss: 0.9030 - val_accuracy: 0.8643 - val_loss: 0.5697\n",
      "Epoch 2/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8698 - loss: 0.5445 - val_accuracy: 0.8687 - val_loss: 0.5452\n",
      "Epoch 3/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.5166 - val_accuracy: 0.8853 - val_loss: 0.5171\n",
      "Epoch 4/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9019 - loss: 0.4721 - val_accuracy: 0.8835 - val_loss: 0.5132\n",
      "Epoch 5/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.4488 - val_accuracy: 0.8955 - val_loss: 0.5005\n",
      "Epoch 6/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.4491 - val_accuracy: 0.8879 - val_loss: 0.5018\n",
      "Epoch 7/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.4365 - val_accuracy: 0.8799 - val_loss: 0.4973\n",
      "Epoch 8/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9226 - loss: 0.4209 - val_accuracy: 0.8938 - val_loss: 0.4914\n",
      "Epoch 9/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9280 - loss: 0.4083 - val_accuracy: 0.8888 - val_loss: 0.4890\n",
      "Epoch 10/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9210 - loss: 0.4075 - val_accuracy: 0.8893 - val_loss: 0.4950\n",
      "Epoch 11/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9314 - loss: 0.3909 - val_accuracy: 0.8938 - val_loss: 0.4787\n",
      "Epoch 12/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9281 - loss: 0.4041 - val_accuracy: 0.8973 - val_loss: 0.4781\n",
      "Epoch 13/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9221 - loss: 0.3997 - val_accuracy: 0.8942 - val_loss: 0.4766\n",
      "Epoch 14/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9353 - loss: 0.3727 - val_accuracy: 0.8951 - val_loss: 0.4835\n",
      "Epoch 15/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9298 - loss: 0.3830 - val_accuracy: 0.9018 - val_loss: 0.4787\n",
      "Epoch 16/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.3639 - val_accuracy: 0.8991 - val_loss: 0.4771\n",
      "Epoch 17/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.3620 - val_accuracy: 0.8946 - val_loss: 0.4668\n",
      "Epoch 18/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.3645 - val_accuracy: 0.9058 - val_loss: 0.4646\n",
      "Epoch 19/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.3548 - val_accuracy: 0.9076 - val_loss: 0.4614\n",
      "Epoch 20/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9426 - loss: 0.3469 - val_accuracy: 0.8996 - val_loss: 0.4583\n",
      "Epoch 21/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9431 - loss: 0.3500 - val_accuracy: 0.9071 - val_loss: 0.4546\n",
      "Epoch 22/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9477 - loss: 0.3369 - val_accuracy: 0.9027 - val_loss: 0.4637\n",
      "Epoch 23/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.3332 - val_accuracy: 0.8888 - val_loss: 0.4686\n",
      "Epoch 24/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.3374 - val_accuracy: 0.8942 - val_loss: 0.4701\n",
      "Epoch 25/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.3343 - val_accuracy: 0.8973 - val_loss: 0.4543\n",
      "Epoch 26/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9473 - loss: 0.3272 - val_accuracy: 0.9071 - val_loss: 0.4480\n",
      "Epoch 27/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9506 - loss: 0.3294 - val_accuracy: 0.9040 - val_loss: 0.4539\n",
      "Epoch 28/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.3274 - val_accuracy: 0.8911 - val_loss: 0.4711\n",
      "Epoch 29/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.3234 - val_accuracy: 0.9009 - val_loss: 0.4584\n",
      "Epoch 30/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.3230 - val_accuracy: 0.9009 - val_loss: 0.4487\n",
      "Epoch 31/100\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9476 - loss: 0.3210 - val_accuracy: 0.8973 - val_loss: 0.4546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7effa6602610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Partimos datos en prueba y Testing\n",
    "\n",
    "#Vectorizaci√≥n\n",
    "#v = CountVectorizer(vocabulary=all_words)\n",
    "v = TfidfVectorizer(vocabulary=all_words)\n",
    "#X_t = v.transform(x).toarray()\n",
    "X_t = v.fit_transform(x).toarray()\n",
    "y_t = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, random_state=42, test_size=0.2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l2(0.003)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.002)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1,validation_data=(X_test, y_test), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/encoder.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "#detenerlo en el epoch 10 11?\n",
    "#45 m√°s viables\n",
    "joblib.dump(model, '../models/RNA5.pkl')\n",
    "joblib.dump(v, '../models/vectorizador.pkl')\n",
    "joblib.dump(encoder, '../models/encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
